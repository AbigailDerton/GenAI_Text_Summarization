# GenAI_Text_Summarization
A demonstration of BART, a transformer-based language model fine-tuned on the CNN/DailyMail dataset, used to summarize a news article on pet adoption.

## Model Summary
BART is a sequence-to-sequence transformer with a bidirectional (BERT-style) encoder and an autoregressive (GPT-style) decoder. It is pre-trained by corrupting input text and learning to reconstruct the original. While BART excels at text generation tasks like summarization and translation, it also performs well on comprehension tasks such as classification and question answering.

## Files
The text_summarization.ipynb file demonstrates how to use a generative AI model for text summarization. It employs BART, a large language model fine-tuned on the CNN/DailyMail dataset, to summarize a news article about animal adoption.
